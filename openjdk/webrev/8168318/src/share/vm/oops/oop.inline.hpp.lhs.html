<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

    <script type="text/javascript" src="../../../../ancnav.js"></script>
    </head>
    <body id="SUNWwebrev" onkeypress="keypress(event);">
    <a name="0"></a>
    <pre></pre><hr></hr>
<pre>
   1 /*
   2  * Copyright (c) 1997, 2016, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #ifndef SHARE_VM_OOPS_OOP_INLINE_HPP
  26 #define SHARE_VM_OOPS_OOP_INLINE_HPP
  27 
  28 #include "gc/shared/ageTable.hpp"
  29 #include "gc/shared/barrierSet.inline.hpp"
  30 #include "gc/shared/cardTableModRefBS.hpp"
  31 #include "gc/shared/collectedHeap.inline.hpp"
  32 #include "gc/shared/genCollectedHeap.hpp"
  33 #include "gc/shared/generation.hpp"
  34 #include "oops/arrayKlass.hpp"
  35 #include "oops/arrayOop.hpp"
  36 #include "oops/klass.inline.hpp"
  37 #include "oops/markOop.inline.hpp"
  38 #include "oops/oop.hpp"
  39 #include "runtime/atomic.hpp"
  40 #include "runtime/orderAccess.inline.hpp"
  41 #include "runtime/os.hpp"
  42 #include "utilities/macros.hpp"
  43 
  44 inline void update_barrier_set(void* p, oop v, bool release = false) {
  45   assert(oopDesc::bs() != NULL, "Uninitialized bs in oop!");
  46   oopDesc::bs()-&gt;write_ref_field(p, v, release);
  47 }
  48 
  49 template &lt;class T&gt; inline void update_barrier_set_pre(T* p, oop v) {
  50   oopDesc::bs()-&gt;write_ref_field_pre(p, v);
  51 }
  52 
  53 template &lt;class T&gt; void oop_store(T* p, oop v) {
  54   if (always_do_update_barrier) {
  55     oop_store((volatile T*)p, v);
  56   } else {
  57     update_barrier_set_pre(p, v);
  58     oopDesc::encode_store_heap_oop(p, v);
  59     // always_do_update_barrier == false =&gt;
  60     // Either we are at a safepoint (in GC) or CMS is not used. In both
  61     // cases it's unnecessary to mark the card as dirty with release sematics.
  62     update_barrier_set((void*)p, v, false /* release */);  // cast away type
  63   }
  64 }
  65 
  66 template &lt;class T&gt; void oop_store(volatile T* p, oop v) {
  67   update_barrier_set_pre((T*)p, v);   // cast away volatile
  68   // Used by release_obj_field_put, so use release_store_ptr.
  69   oopDesc::release_encode_store_heap_oop(p, v);
  70   // When using CMS we must mark the card corresponding to p as dirty
  71   // with release sematics to prevent that CMS sees the dirty card but
  72   // not the new value v at p due to reordering of the two
  73   // stores. Note that CMS has a concurrent precleaning phase, where
  74   // it reads the card table while the Java threads are running.
  75   update_barrier_set((void*)p, v, true /* release */);    // cast away type
  76 }
  77 
  78 // Should replace *addr = oop assignments where addr type depends on UseCompressedOops
  79 // (without having to remember the function name this calls).
  80 inline void oop_store_raw(HeapWord* addr, oop value) {
  81   if (UseCompressedOops) {
  82     oopDesc::encode_store_heap_oop((narrowOop*)addr, value);
  83   } else {
  84     oopDesc::encode_store_heap_oop((oop*)addr, value);
  85   }
  86 }
  87 
  88 // Implementation of all inlined member functions defined in oop.hpp
  89 // We need a separate file to avoid circular references
  90 
  91 void oopDesc::release_set_mark(markOop m) {
  92   OrderAccess::release_store_ptr(&amp;_mark, m);
  93 }
  94 
  95 markOop oopDesc::cas_set_mark(markOop new_mark, markOop old_mark) {
  96   return (markOop) Atomic::cmpxchg_ptr(new_mark, &amp;_mark, old_mark);
  97 }
  98 
  99 void oopDesc::init_mark() {
 100   set_mark(markOopDesc::prototype_for_object(this));
 101 }
 102 
 103 Klass* oopDesc::klass() const {
 104   if (UseCompressedClassPointers) {
 105     return Klass::decode_klass_not_null(_metadata._compressed_klass);
 106   } else {
 107     return _metadata._klass;
 108   }
 109 }
 110 
 111 Klass* oopDesc::klass_or_null() const volatile {
<a name="1" id="anc1"></a><span class="removed"> 112   // can be NULL in CMS</span>
 113   if (UseCompressedClassPointers) {
 114     return Klass::decode_klass(_metadata._compressed_klass);
 115   } else {
 116     return _metadata._klass;
<a name="2" id="anc2"></a>










 117   }
 118 }
 119 
 120 Klass** oopDesc::klass_addr() {
 121   // Only used internally and with CMS and will not work with
 122   // UseCompressedOops
 123   assert(!UseCompressedClassPointers, "only supported with uncompressed klass pointers");
 124   return (Klass**) &amp;_metadata._klass;
 125 }
 126 
 127 narrowKlass* oopDesc::compressed_klass_addr() {
 128   assert(UseCompressedClassPointers, "only called by compressed klass pointers");
 129   return &amp;_metadata._compressed_klass;
 130 }
 131 
 132 #define CHECK_SET_KLASS(k)                                                \
 133   do {                                                                    \
 134     assert(Universe::is_bootstrapping() || k != NULL, "NULL Klass");      \
 135     assert(Universe::is_bootstrapping() || k-&gt;is_klass(), "not a Klass"); \
 136   } while (0)
 137 
 138 void oopDesc::set_klass(Klass* k) {
 139   CHECK_SET_KLASS(k);
 140   if (UseCompressedClassPointers) {
 141     *compressed_klass_addr() = Klass::encode_klass_not_null(k);
 142   } else {
 143     *klass_addr() = k;
 144   }
 145 }
 146 
 147 void oopDesc::release_set_klass(Klass* k) {
 148   CHECK_SET_KLASS(k);
 149   if (UseCompressedClassPointers) {
 150     OrderAccess::release_store(compressed_klass_addr(),
 151                                Klass::encode_klass_not_null(k));
 152   } else {
 153     OrderAccess::release_store_ptr(klass_addr(), k);
 154   }
 155 }
 156 
 157 #undef CHECK_SET_KLASS
 158 
 159 int oopDesc::klass_gap() const {
 160   return *(int*)(((intptr_t)this) + klass_gap_offset_in_bytes());
 161 }
 162 
 163 void oopDesc::set_klass_gap(int v) {
 164   if (UseCompressedClassPointers) {
 165     *(int*)(((intptr_t)this) + klass_gap_offset_in_bytes()) = v;
 166   }
 167 }
 168 
 169 void oopDesc::set_klass_to_list_ptr(oop k) {
 170   // This is only to be used during GC, for from-space objects, so no
 171   // barrier is needed.
 172   if (UseCompressedClassPointers) {
 173     _metadata._compressed_klass = (narrowKlass)encode_heap_oop(k);  // may be null (parnew overflow handling)
 174   } else {
 175     _metadata._klass = (Klass*)(address)k;
 176   }
 177 }
 178 
 179 oop oopDesc::list_ptr_from_klass() {
 180   // This is only to be used during GC, for from-space objects.
 181   if (UseCompressedClassPointers) {
 182     return decode_heap_oop((narrowOop)_metadata._compressed_klass);
 183   } else {
 184     // Special case for GC
 185     return (oop)(address)_metadata._klass;
 186   }
 187 }
 188 
 189 bool oopDesc::is_a(Klass* k) const {
 190   return klass()-&gt;is_subtype_of(k);
 191 }
 192 
 193 int oopDesc::size()  {
 194   return size_given_klass(klass());
 195 }
 196 
 197 int oopDesc::size_given_klass(Klass* klass)  {
 198   int lh = klass-&gt;layout_helper();
 199   int s;
 200 
 201   // lh is now a value computed at class initialization that may hint
 202   // at the size.  For instances, this is positive and equal to the
 203   // size.  For arrays, this is negative and provides log2 of the
 204   // array element size.  For other oops, it is zero and thus requires
 205   // a virtual call.
 206   //
 207   // We go to all this trouble because the size computation is at the
 208   // heart of phase 2 of mark-compaction, and called for every object,
 209   // alive or dead.  So the speed here is equal in importance to the
 210   // speed of allocation.
 211 
 212   if (lh &gt; Klass::_lh_neutral_value) {
 213     if (!Klass::layout_helper_needs_slow_path(lh)) {
 214       s = lh &gt;&gt; LogHeapWordSize;  // deliver size scaled by wordSize
 215     } else {
 216       s = klass-&gt;oop_size(this);
 217     }
 218   } else if (lh &lt;= Klass::_lh_neutral_value) {
 219     // The most common case is instances; fall through if so.
 220     if (lh &lt; Klass::_lh_neutral_value) {
 221       // Second most common case is arrays.  We have to fetch the
 222       // length of the array, shift (multiply) it appropriately,
 223       // up to wordSize, add the header, and align to object size.
 224       size_t size_in_bytes;
 225 #ifdef _M_IA64
 226       // The Windows Itanium Aug 2002 SDK hoists this load above
 227       // the check for s &lt; 0.  An oop at the end of the heap will
 228       // cause an access violation if this load is performed on a non
 229       // array oop.  Making the reference volatile prohibits this.
 230       // (%%% please explain by what magic the length is actually fetched!)
 231       volatile int *array_length;
 232       array_length = (volatile int *)( (intptr_t)this +
 233                           arrayOopDesc::length_offset_in_bytes() );
 234       assert(array_length &gt; 0, "Integer arithmetic problem somewhere");
 235       // Put into size_t to avoid overflow.
 236       size_in_bytes = (size_t) array_length;
 237       size_in_bytes = size_in_bytes &lt;&lt; Klass::layout_helper_log2_element_size(lh);
 238 #else
 239       size_t array_length = (size_t) ((arrayOop)this)-&gt;length();
 240       size_in_bytes = array_length &lt;&lt; Klass::layout_helper_log2_element_size(lh);
 241 #endif
 242       size_in_bytes += Klass::layout_helper_header_size(lh);
 243 
 244       // This code could be simplified, but by keeping array_header_in_bytes
 245       // in units of bytes and doing it this way we can round up just once,
 246       // skipping the intermediate round to HeapWordSize.  Cast the result
 247       // of round_to to size_t to guarantee unsigned division == right shift.
 248       s = (int)((size_t)round_to(size_in_bytes, MinObjAlignmentInBytes) /
 249         HeapWordSize);
 250 
 251       // ParNew (used by CMS), UseParallelGC and UseG1GC can change the length field
 252       // of an "old copy" of an object array in the young gen so it indicates
 253       // the grey portion of an already copied array. This will cause the first
 254       // disjunct below to fail if the two comparands are computed across such
 255       // a concurrent change.
 256       // ParNew also runs with promotion labs (which look like int
 257       // filler arrays) which are subject to changing their declared size
 258       // when finally retiring a PLAB; this also can cause the first disjunct
 259       // to fail for another worker thread that is concurrently walking the block
 260       // offset table. Both these invariant failures are benign for their
 261       // current uses; we relax the assertion checking to cover these two cases below:
 262       //     is_objArray() &amp;&amp; is_forwarded()   // covers first scenario above
 263       //  || is_typeArray()                    // covers second scenario above
 264       // If and when UseParallelGC uses the same obj array oop stealing/chunking
 265       // technique, we will need to suitably modify the assertion.
 266       assert((s == klass-&gt;oop_size(this)) ||
 267              (Universe::heap()-&gt;is_gc_active() &amp;&amp;
 268               ((is_typeArray() &amp;&amp; UseConcMarkSweepGC) ||
 269                (is_objArray()  &amp;&amp; is_forwarded() &amp;&amp; (UseConcMarkSweepGC || UseParallelGC || UseG1GC)))),
 270              "wrong array object size");
 271     } else {
 272       // Must be zero, so bite the bullet and take the virtual call.
 273       s = klass-&gt;oop_size(this);
 274     }
 275   }
 276 
 277   assert(s % MinObjAlignment == 0, "Oop size is not properly aligned: %d", s);
 278   assert(s &gt; 0, "Oop size must be greater than zero, not %d", s);
 279   return s;
 280 }
 281 
 282 bool oopDesc::is_instance()  const { return klass()-&gt;is_instance_klass();  }
 283 bool oopDesc::is_array()     const { return klass()-&gt;is_array_klass();     }
 284 bool oopDesc::is_objArray()  const { return klass()-&gt;is_objArray_klass();  }
 285 bool oopDesc::is_typeArray() const { return klass()-&gt;is_typeArray_klass(); }
 286 
 287 void*      oopDesc::field_base(int offset)          const { return (void*)&amp;((char*)this)[offset]; }
 288 
 289 jbyte*     oopDesc::byte_field_addr(int offset)     const { return (jbyte*)    field_base(offset); }
 290 jchar*     oopDesc::char_field_addr(int offset)     const { return (jchar*)    field_base(offset); }
 291 jboolean*  oopDesc::bool_field_addr(int offset)     const { return (jboolean*) field_base(offset); }
 292 jint*      oopDesc::int_field_addr(int offset)      const { return (jint*)     field_base(offset); }
 293 jshort*    oopDesc::short_field_addr(int offset)    const { return (jshort*)   field_base(offset); }
 294 jlong*     oopDesc::long_field_addr(int offset)     const { return (jlong*)    field_base(offset); }
 295 jfloat*    oopDesc::float_field_addr(int offset)    const { return (jfloat*)   field_base(offset); }
 296 jdouble*   oopDesc::double_field_addr(int offset)   const { return (jdouble*)  field_base(offset); }
 297 Metadata** oopDesc::metadata_field_addr(int offset) const { return (Metadata**)field_base(offset); }
 298 
 299 template &lt;class T&gt; T* oopDesc::obj_field_addr(int offset) const { return (T*)  field_base(offset); }
 300 address*   oopDesc::address_field_addr(int offset)  const { return (address*)  field_base(offset); }
 301 
 302 
 303 // Functions for getting and setting oops within instance objects.
 304 // If the oops are compressed, the type passed to these overloaded functions
 305 // is narrowOop.  All functions are overloaded so they can be called by
 306 // template functions without conditionals (the compiler instantiates via
 307 // the right type and inlines the appopriate code).
 308 
 309 // Algorithm for encoding and decoding oops from 64 bit pointers to 32 bit
 310 // offset from the heap base.  Saving the check for null can save instructions
 311 // in inner GC loops so these are separated.
 312 
 313 inline bool check_obj_alignment(oop obj) {
 314   return (cast_from_oop&lt;intptr_t&gt;(obj) &amp; MinObjAlignmentInBytesMask) == 0;
 315 }
 316 
 317 oop oopDesc::decode_heap_oop_not_null(narrowOop v) {
 318   assert(!is_null(v), "narrow oop value can never be zero");
 319   address base = Universe::narrow_oop_base();
 320   int    shift = Universe::narrow_oop_shift();
 321   oop result = (oop)(void*)((uintptr_t)base + ((uintptr_t)v &lt;&lt; shift));
 322   assert(check_obj_alignment(result), "address not aligned: " INTPTR_FORMAT, p2i((void*) result));
 323   return result;
 324 }
 325 
 326 oop oopDesc::decode_heap_oop(narrowOop v) {
 327   return is_null(v) ? (oop)NULL : decode_heap_oop_not_null(v);
 328 }
 329 
 330 narrowOop oopDesc::encode_heap_oop_not_null(oop v) {
 331   assert(!is_null(v), "oop value can never be zero");
 332   assert(check_obj_alignment(v), "Address not aligned");
 333   assert(Universe::heap()-&gt;is_in_reserved(v), "Address not in heap");
 334   address base = Universe::narrow_oop_base();
 335   int    shift = Universe::narrow_oop_shift();
 336   uint64_t  pd = (uint64_t)(pointer_delta((void*)v, (void*)base, 1));
 337   assert(OopEncodingHeapMax &gt; pd, "change encoding max if new encoding");
 338   uint64_t result = pd &gt;&gt; shift;
 339   assert((result &amp; CONST64(0xffffffff00000000)) == 0, "narrow oop overflow");
 340   assert(decode_heap_oop(result) == v, "reversibility");
 341   return (narrowOop)result;
 342 }
 343 
 344 narrowOop oopDesc::encode_heap_oop(oop v) {
 345   return (is_null(v)) ? (narrowOop)0 : encode_heap_oop_not_null(v);
 346 }
 347 
 348 // Load and decode an oop out of the Java heap into a wide oop.
 349 oop oopDesc::load_decode_heap_oop_not_null(narrowOop* p) {
 350   return decode_heap_oop_not_null(*p);
 351 }
 352 
 353 // Load and decode an oop out of the heap accepting null
 354 oop oopDesc::load_decode_heap_oop(narrowOop* p) {
 355   return decode_heap_oop(*p);
 356 }
 357 
 358 // Encode and store a heap oop.
 359 void oopDesc::encode_store_heap_oop_not_null(narrowOop* p, oop v) {
 360   *p = encode_heap_oop_not_null(v);
 361 }
 362 
 363 // Encode and store a heap oop allowing for null.
 364 void oopDesc::encode_store_heap_oop(narrowOop* p, oop v) {
 365   *p = encode_heap_oop(v);
 366 }
 367 
 368 // Store heap oop as is for volatile fields.
 369 void oopDesc::release_store_heap_oop(volatile oop* p, oop v) {
 370   OrderAccess::release_store_ptr(p, v);
 371 }
 372 void oopDesc::release_store_heap_oop(volatile narrowOop* p, narrowOop v) {
 373   OrderAccess::release_store(p, v);
 374 }
 375 
 376 void oopDesc::release_encode_store_heap_oop_not_null(volatile narrowOop* p, oop v) {
 377   // heap oop is not pointer sized.
 378   OrderAccess::release_store(p, encode_heap_oop_not_null(v));
 379 }
 380 void oopDesc::release_encode_store_heap_oop_not_null(volatile oop* p, oop v) {
 381   OrderAccess::release_store_ptr(p, v);
 382 }
 383 
 384 void oopDesc::release_encode_store_heap_oop(volatile oop* p, oop v) {
 385   OrderAccess::release_store_ptr(p, v);
 386 }
 387 void oopDesc::release_encode_store_heap_oop(volatile narrowOop* p, oop v) {
 388   OrderAccess::release_store(p, encode_heap_oop(v));
 389 }
 390 
 391 // These functions are only used to exchange oop fields in instances,
 392 // not headers.
 393 oop oopDesc::atomic_exchange_oop(oop exchange_value, volatile HeapWord *dest) {
 394   if (UseCompressedOops) {
 395     // encode exchange value from oop to T
 396     narrowOop val = encode_heap_oop(exchange_value);
 397     narrowOop old = (narrowOop)Atomic::xchg(val, (narrowOop*)dest);
 398     // decode old from T to oop
 399     return decode_heap_oop(old);
 400   } else {
 401     return (oop)Atomic::xchg_ptr(exchange_value, (oop*)dest);
 402   }
 403 }
 404 
 405 oop oopDesc::atomic_compare_exchange_oop(oop exchange_value,
 406                                          volatile HeapWord *dest,
 407                                          oop compare_value,
 408                                          bool prebarrier) {
 409   if (UseCompressedOops) {
 410     if (prebarrier) {
 411       update_barrier_set_pre((narrowOop*)dest, exchange_value);
 412     }
 413     // encode exchange and compare value from oop to T
 414     narrowOop val = encode_heap_oop(exchange_value);
 415     narrowOop cmp = encode_heap_oop(compare_value);
 416 
 417     narrowOop old = (narrowOop) Atomic::cmpxchg(val, (narrowOop*)dest, cmp);
 418     // decode old from T to oop
 419     return decode_heap_oop(old);
 420   } else {
 421     if (prebarrier) {
 422       update_barrier_set_pre((oop*)dest, exchange_value);
 423     }
 424     return (oop)Atomic::cmpxchg_ptr(exchange_value, (oop*)dest, compare_value);
 425   }
 426 }
 427 
 428 // In order to put or get a field out of an instance, must first check
 429 // if the field has been compressed and uncompress it.
 430 oop oopDesc::obj_field(int offset) const {
 431   return UseCompressedOops ?
 432     load_decode_heap_oop(obj_field_addr&lt;narrowOop&gt;(offset)) :
 433     load_decode_heap_oop(obj_field_addr&lt;oop&gt;(offset));
 434 }
 435 
 436 void oopDesc::obj_field_put(int offset, oop value) {
 437   UseCompressedOops ? oop_store(obj_field_addr&lt;narrowOop&gt;(offset), value) :
 438                       oop_store(obj_field_addr&lt;oop&gt;(offset),       value);
 439 }
 440 
 441 void oopDesc::obj_field_put_raw(int offset, oop value) {
 442   UseCompressedOops ?
 443     encode_store_heap_oop(obj_field_addr&lt;narrowOop&gt;(offset), value) :
 444     encode_store_heap_oop(obj_field_addr&lt;oop&gt;(offset),       value);
 445 }
 446 void oopDesc::obj_field_put_volatile(int offset, oop value) {
 447   OrderAccess::release();
 448   obj_field_put(offset, value);
 449   OrderAccess::fence();
 450 }
 451 
 452 Metadata* oopDesc::metadata_field(int offset) const           { return *metadata_field_addr(offset);   }
 453 void oopDesc::metadata_field_put(int offset, Metadata* value) { *metadata_field_addr(offset) = value;  }
 454 
 455 jbyte oopDesc::byte_field(int offset) const                   { return (jbyte) *byte_field_addr(offset);    }
 456 void oopDesc::byte_field_put(int offset, jbyte contents)      { *byte_field_addr(offset) = (jint) contents; }
 457 
 458 jchar oopDesc::char_field(int offset) const                   { return (jchar) *char_field_addr(offset);    }
 459 void oopDesc::char_field_put(int offset, jchar contents)      { *char_field_addr(offset) = (jint) contents; }
 460 
 461 jboolean oopDesc::bool_field(int offset) const                { return (jboolean) *bool_field_addr(offset); }
 462 void oopDesc::bool_field_put(int offset, jboolean contents)   { *bool_field_addr(offset) = (((jint) contents) &amp; 1); }
 463 
 464 jint oopDesc::int_field(int offset) const                     { return *int_field_addr(offset);        }
 465 void oopDesc::int_field_put(int offset, jint contents)        { *int_field_addr(offset) = contents;    }
 466 
 467 jshort oopDesc::short_field(int offset) const                 { return (jshort) *short_field_addr(offset);  }
 468 void oopDesc::short_field_put(int offset, jshort contents)    { *short_field_addr(offset) = (jint) contents;}
 469 
 470 jlong oopDesc::long_field(int offset) const                   { return *long_field_addr(offset);       }
 471 void oopDesc::long_field_put(int offset, jlong contents)      { *long_field_addr(offset) = contents;   }
 472 
 473 jfloat oopDesc::float_field(int offset) const                 { return *float_field_addr(offset);      }
 474 void oopDesc::float_field_put(int offset, jfloat contents)    { *float_field_addr(offset) = contents;  }
 475 
 476 jdouble oopDesc::double_field(int offset) const               { return *double_field_addr(offset);     }
 477 void oopDesc::double_field_put(int offset, jdouble contents)  { *double_field_addr(offset) = contents; }
 478 
 479 address oopDesc::address_field(int offset) const              { return *address_field_addr(offset);     }
 480 void oopDesc::address_field_put(int offset, address contents) { *address_field_addr(offset) = contents; }
 481 
 482 oop oopDesc::obj_field_acquire(int offset) const {
 483   return UseCompressedOops ?
 484              decode_heap_oop((narrowOop)
 485                OrderAccess::load_acquire(obj_field_addr&lt;narrowOop&gt;(offset)))
 486            : decode_heap_oop((oop)
 487                OrderAccess::load_ptr_acquire(obj_field_addr&lt;oop&gt;(offset)));
 488 }
 489 void oopDesc::release_obj_field_put(int offset, oop value) {
 490   UseCompressedOops ?
 491     oop_store((volatile narrowOop*)obj_field_addr&lt;narrowOop&gt;(offset), value) :
 492     oop_store((volatile oop*)      obj_field_addr&lt;oop&gt;(offset),       value);
 493 }
 494 
 495 jbyte oopDesc::byte_field_acquire(int offset) const                   { return OrderAccess::load_acquire(byte_field_addr(offset));     }
 496 void oopDesc::release_byte_field_put(int offset, jbyte contents)      { OrderAccess::release_store(byte_field_addr(offset), contents); }
 497 
 498 jchar oopDesc::char_field_acquire(int offset) const                   { return OrderAccess::load_acquire(char_field_addr(offset));     }
 499 void oopDesc::release_char_field_put(int offset, jchar contents)      { OrderAccess::release_store(char_field_addr(offset), contents); }
 500 
 501 jboolean oopDesc::bool_field_acquire(int offset) const                { return OrderAccess::load_acquire(bool_field_addr(offset));     }
 502 void oopDesc::release_bool_field_put(int offset, jboolean contents)   { OrderAccess::release_store(bool_field_addr(offset), (contents &amp; 1)); }
 503 
 504 jint oopDesc::int_field_acquire(int offset) const                     { return OrderAccess::load_acquire(int_field_addr(offset));      }
 505 void oopDesc::release_int_field_put(int offset, jint contents)        { OrderAccess::release_store(int_field_addr(offset), contents);  }
 506 
 507 jshort oopDesc::short_field_acquire(int offset) const                 { return (jshort)OrderAccess::load_acquire(short_field_addr(offset)); }
 508 void oopDesc::release_short_field_put(int offset, jshort contents)    { OrderAccess::release_store(short_field_addr(offset), contents);     }
 509 
 510 jlong oopDesc::long_field_acquire(int offset) const                   { return OrderAccess::load_acquire(long_field_addr(offset));       }
 511 void oopDesc::release_long_field_put(int offset, jlong contents)      { OrderAccess::release_store(long_field_addr(offset), contents);   }
 512 
 513 jfloat oopDesc::float_field_acquire(int offset) const                 { return OrderAccess::load_acquire(float_field_addr(offset));      }
 514 void oopDesc::release_float_field_put(int offset, jfloat contents)    { OrderAccess::release_store(float_field_addr(offset), contents);  }
 515 
 516 jdouble oopDesc::double_field_acquire(int offset) const               { return OrderAccess::load_acquire(double_field_addr(offset));     }
 517 void oopDesc::release_double_field_put(int offset, jdouble contents)  { OrderAccess::release_store(double_field_addr(offset), contents); }
 518 
 519 address oopDesc::address_field_acquire(int offset) const              { return (address) OrderAccess::load_ptr_acquire(address_field_addr(offset)); }
 520 void oopDesc::release_address_field_put(int offset, address contents) { OrderAccess::release_store_ptr(address_field_addr(offset), contents); }
 521 
 522 bool oopDesc::is_locked() const {
 523   return mark()-&gt;is_locked();
 524 }
 525 
 526 bool oopDesc::is_unlocked() const {
 527   return mark()-&gt;is_unlocked();
 528 }
 529 
 530 bool oopDesc::has_bias_pattern() const {
 531   return mark()-&gt;has_bias_pattern();
 532 }
 533 
 534 // used only for asserts
 535 bool oopDesc::is_oop(bool ignore_mark_word) const {
 536   oop obj = (oop) this;
 537   if (!check_obj_alignment(obj)) return false;
 538   if (!Universe::heap()-&gt;is_in_reserved(obj)) return false;
 539   // obj is aligned and accessible in heap
 540   if (Universe::heap()-&gt;is_in_reserved(obj-&gt;klass_or_null())) return false;
 541 
 542   // Header verification: the mark is typically non-NULL. If we're
 543   // at a safepoint, it must not be null.
 544   // Outside of a safepoint, the header could be changing (for example,
 545   // another thread could be inflating a lock on this object).
 546   if (ignore_mark_word) {
 547     return true;
 548   }
 549   if (mark() != NULL) {
 550     return true;
 551   }
 552   return !SafepointSynchronize::is_at_safepoint();
 553 }
 554 
 555 
 556 // used only for asserts
 557 bool oopDesc::is_oop_or_null(bool ignore_mark_word) const {
 558   return this == NULL ? true : is_oop(ignore_mark_word);
 559 }
 560 
 561 #ifndef PRODUCT
 562 // used only for asserts
 563 bool oopDesc::is_unlocked_oop() const {
 564   if (!Universe::heap()-&gt;is_in_reserved(this)) return false;
 565   return mark()-&gt;is_unlocked();
 566 }
 567 #endif // PRODUCT
 568 
 569 // Used only for markSweep, scavenging
 570 bool oopDesc::is_gc_marked() const {
 571   return mark()-&gt;is_marked();
 572 }
 573 
 574 bool oopDesc::is_scavengable() const {
 575   return Universe::heap()-&gt;is_scavengable(this);
 576 }
 577 
 578 // Used by scavengers
 579 bool oopDesc::is_forwarded() const {
 580   // The extra heap check is needed since the obj might be locked, in which case the
 581   // mark would point to a stack location and have the sentinel bit cleared
 582   return mark()-&gt;is_marked();
 583 }
 584 
 585 // Used by scavengers
 586 void oopDesc::forward_to(oop p) {
 587   assert(check_obj_alignment(p),
 588          "forwarding to something not aligned");
 589   assert(Universe::heap()-&gt;is_in_reserved(p),
 590          "forwarding to something not in heap");
 591   markOop m = markOopDesc::encode_pointer_as_mark(p);
 592   assert(m-&gt;decode_pointer() == p, "encoding must be reversable");
 593   set_mark(m);
 594 }
 595 
 596 // Used by parallel scavengers
 597 bool oopDesc::cas_forward_to(oop p, markOop compare) {
 598   assert(check_obj_alignment(p),
 599          "forwarding to something not aligned");
 600   assert(Universe::heap()-&gt;is_in_reserved(p),
 601          "forwarding to something not in heap");
 602   markOop m = markOopDesc::encode_pointer_as_mark(p);
 603   assert(m-&gt;decode_pointer() == p, "encoding must be reversable");
 604   return cas_set_mark(m, compare) == compare;
 605 }
 606 
 607 #if INCLUDE_ALL_GCS
 608 oop oopDesc::forward_to_atomic(oop p) {
 609   markOop oldMark = mark();
 610   markOop forwardPtrMark = markOopDesc::encode_pointer_as_mark(p);
 611   markOop curMark;
 612 
 613   assert(forwardPtrMark-&gt;decode_pointer() == p, "encoding must be reversable");
 614   assert(sizeof(markOop) == sizeof(intptr_t), "CAS below requires this.");
 615 
 616   while (!oldMark-&gt;is_marked()) {
 617     curMark = (markOop)Atomic::cmpxchg_ptr(forwardPtrMark, &amp;_mark, oldMark);
 618     assert(is_forwarded(), "object should have been forwarded");
 619     if (curMark == oldMark) {
 620       return NULL;
 621     }
 622     // If the CAS was unsuccessful then curMark-&gt;is_marked()
 623     // should return true as another thread has CAS'd in another
 624     // forwarding pointer.
 625     oldMark = curMark;
 626   }
 627   return forwardee();
 628 }
 629 #endif
 630 
 631 // Note that the forwardee is not the same thing as the displaced_mark.
 632 // The forwardee is used when copying during scavenge and mark-sweep.
 633 // It does need to clear the low two locking- and GC-related bits.
 634 oop oopDesc::forwardee() const {
 635   return (oop) mark()-&gt;decode_pointer();
 636 }
 637 
 638 // The following method needs to be MT safe.
 639 uint oopDesc::age() const {
 640   assert(!is_forwarded(), "Attempt to read age from forwarded mark");
 641   if (has_displaced_mark()) {
 642     return displaced_mark()-&gt;age();
 643   } else {
 644     return mark()-&gt;age();
 645   }
 646 }
 647 
 648 void oopDesc::incr_age() {
 649   assert(!is_forwarded(), "Attempt to increment age of forwarded mark");
 650   if (has_displaced_mark()) {
 651     set_displaced_mark(displaced_mark()-&gt;incr_age());
 652   } else {
 653     set_mark(mark()-&gt;incr_age());
 654   }
 655 }
 656 
 657 int oopDesc::ms_adjust_pointers() {
 658   debug_only(int check_size = size());
 659   int s = klass()-&gt;oop_ms_adjust_pointers(this);
 660   assert(s == check_size, "should be the same");
 661   return s;
 662 }
 663 
 664 #if INCLUDE_ALL_GCS
 665 void oopDesc::pc_follow_contents(ParCompactionManager* cm) {
 666   klass()-&gt;oop_pc_follow_contents(this, cm);
 667 }
 668 
 669 void oopDesc::pc_update_contents(ParCompactionManager* cm) {
 670   Klass* k = klass();
 671   if (!k-&gt;is_typeArray_klass()) {
 672     // It might contain oops beyond the header, so take the virtual call.
 673     k-&gt;oop_pc_update_pointers(this, cm);
 674   }
 675   // Else skip it.  The TypeArrayKlass in the header never needs scavenging.
 676 }
 677 
 678 void oopDesc::ps_push_contents(PSPromotionManager* pm) {
 679   Klass* k = klass();
 680   if (!k-&gt;is_typeArray_klass()) {
 681     // It might contain oops beyond the header, so take the virtual call.
 682     k-&gt;oop_ps_push_contents(this, pm);
 683   }
 684   // Else skip it.  The TypeArrayKlass in the header never needs scavenging.
 685 }
 686 #endif // INCLUDE_ALL_GCS
 687 
 688 #define OOP_ITERATE_DEFN(OopClosureType, nv_suffix)                 \
 689                                                                     \
 690 void oopDesc::oop_iterate(OopClosureType* blk) {                    \
 691   klass()-&gt;oop_oop_iterate##nv_suffix(this, blk);                   \
 692 }                                                                   \
 693                                                                     \
 694 void oopDesc::oop_iterate(OopClosureType* blk, MemRegion mr) {      \
 695   klass()-&gt;oop_oop_iterate_bounded##nv_suffix(this, blk, mr);       \
 696 }
 697 
 698 #define OOP_ITERATE_SIZE_DEFN(OopClosureType, nv_suffix)            \
 699                                                                     \
 700 int oopDesc::oop_iterate_size(OopClosureType* blk) {                \
 701   Klass* k = klass();                                               \
 702   int size = size_given_klass(k);                                   \
 703   k-&gt;oop_oop_iterate##nv_suffix(this, blk);                         \
 704   return size;                                                      \
 705 }                                                                   \
 706                                                                     \
 707 int oopDesc::oop_iterate_size(OopClosureType* blk, MemRegion mr) {  \
 708   Klass* k = klass();                                               \
 709   int size = size_given_klass(k);                                   \
 710   k-&gt;oop_oop_iterate_bounded##nv_suffix(this, blk, mr);             \
 711   return size;                                                      \
 712 }
 713 
 714 int oopDesc::oop_iterate_no_header(OopClosure* blk) {
 715   // The NoHeaderExtendedOopClosure wraps the OopClosure and proxies all
 716   // the do_oop calls, but turns off all other features in ExtendedOopClosure.
 717   NoHeaderExtendedOopClosure cl(blk);
 718   return oop_iterate_size(&amp;cl);
 719 }
 720 
 721 int oopDesc::oop_iterate_no_header(OopClosure* blk, MemRegion mr) {
 722   NoHeaderExtendedOopClosure cl(blk);
 723   return oop_iterate_size(&amp;cl, mr);
 724 }
 725 
 726 #if INCLUDE_ALL_GCS
 727 #define OOP_ITERATE_BACKWARDS_DEFN(OopClosureType, nv_suffix)       \
 728                                                                     \
 729 inline void oopDesc::oop_iterate_backwards(OopClosureType* blk) {   \
 730   klass()-&gt;oop_oop_iterate_backwards##nv_suffix(this, blk);         \
 731 }
 732 #else
 733 #define OOP_ITERATE_BACKWARDS_DEFN(OopClosureType, nv_suffix)
 734 #endif // INCLUDE_ALL_GCS
 735 
 736 #define ALL_OOPDESC_OOP_ITERATE(OopClosureType, nv_suffix)  \
 737   OOP_ITERATE_DEFN(OopClosureType, nv_suffix)               \
 738   OOP_ITERATE_SIZE_DEFN(OopClosureType, nv_suffix)          \
 739   OOP_ITERATE_BACKWARDS_DEFN(OopClosureType, nv_suffix)
 740 
 741 ALL_OOP_OOP_ITERATE_CLOSURES_1(ALL_OOPDESC_OOP_ITERATE)
 742 ALL_OOP_OOP_ITERATE_CLOSURES_2(ALL_OOPDESC_OOP_ITERATE)
 743 
 744 intptr_t oopDesc::identity_hash() {
 745   // Fast case; if the object is unlocked and the hash value is set, no locking is needed
 746   // Note: The mark must be read into local variable to avoid concurrent updates.
 747   markOop mrk = mark();
 748   if (mrk-&gt;is_unlocked() &amp;&amp; !mrk-&gt;has_no_hash()) {
 749     return mrk-&gt;hash();
 750   } else if (mrk-&gt;is_marked()) {
 751     return mrk-&gt;hash();
 752   } else {
 753     return slow_identity_hash();
 754   }
 755 }
 756 
 757 bool oopDesc::has_displaced_mark() const {
 758   return mark()-&gt;has_displaced_mark_helper();
 759 }
 760 
 761 markOop oopDesc::displaced_mark() const {
 762   return mark()-&gt;displaced_mark_helper();
 763 }
 764 
 765 void oopDesc::set_displaced_mark(markOop m) {
 766   mark()-&gt;set_displaced_mark_helper(m);
 767 }
 768 
 769 #endif // SHARE_VM_OOPS_OOP_INLINE_HPP
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>















































































</pre><form name="eof"><input name="value" value="3" type="hidden" /></form></body></html>
